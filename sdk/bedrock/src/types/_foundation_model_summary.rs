// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>Summary information for a foundation model.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct FoundationModelSummary {
    /// <p>The ARN of the foundation model.</p>
    pub model_arn: ::std::option::Option<::std::string::String>,
    /// <p>The model Id of the foundation model.</p>
    pub model_id: ::std::option::Option<::std::string::String>,
    /// <p>The name of the model.</p>
    pub model_name: ::std::option::Option<::std::string::String>,
    /// <p>The model's provider name.</p>
    pub provider_name: ::std::option::Option<::std::string::String>,
    /// <p>The input modalities that the model supports.</p>
    pub input_modalities: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>,
    /// <p>The output modalities that the model supports.</p>
    pub output_modalities: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>,
    /// <p>Indicates whether the model supports streaming.</p>
    pub response_streaming_supported: ::std::option::Option<bool>,
    /// <p>Whether the model supports fine-tuning or continual pre-training.</p>
    pub customizations_supported: ::std::option::Option<::std::vec::Vec<crate::types::ModelCustomization>>,
    /// <p>The inference types that the model supports.</p>
    pub inference_types_supported: ::std::option::Option<::std::vec::Vec<crate::types::InferenceType>>,
}
impl FoundationModelSummary {
    /// <p>The ARN of the foundation model.</p>
    pub fn model_arn(&self) -> ::std::option::Option<&str> {
        self.model_arn.as_deref()
    }
    /// <p>The model Id of the foundation model.</p>
    pub fn model_id(&self) -> ::std::option::Option<&str> {
        self.model_id.as_deref()
    }
    /// <p>The name of the model.</p>
    pub fn model_name(&self) -> ::std::option::Option<&str> {
        self.model_name.as_deref()
    }
    /// <p>The model's provider name.</p>
    pub fn provider_name(&self) -> ::std::option::Option<&str> {
        self.provider_name.as_deref()
    }
    /// <p>The input modalities that the model supports.</p>
    pub fn input_modalities(&self) -> ::std::option::Option<&[crate::types::ModelModality]> {
        self.input_modalities.as_deref()
    }
    /// <p>The output modalities that the model supports.</p>
    pub fn output_modalities(&self) -> ::std::option::Option<&[crate::types::ModelModality]> {
        self.output_modalities.as_deref()
    }
    /// <p>Indicates whether the model supports streaming.</p>
    pub fn response_streaming_supported(&self) -> ::std::option::Option<bool> {
        self.response_streaming_supported
    }
    /// <p>Whether the model supports fine-tuning or continual pre-training.</p>
    pub fn customizations_supported(&self) -> ::std::option::Option<&[crate::types::ModelCustomization]> {
        self.customizations_supported.as_deref()
    }
    /// <p>The inference types that the model supports.</p>
    pub fn inference_types_supported(&self) -> ::std::option::Option<&[crate::types::InferenceType]> {
        self.inference_types_supported.as_deref()
    }
}
impl FoundationModelSummary {
    /// Creates a new builder-style object to manufacture [`FoundationModelSummary`](crate::types::FoundationModelSummary).
    pub fn builder() -> crate::types::builders::FoundationModelSummaryBuilder {
        crate::types::builders::FoundationModelSummaryBuilder::default()
    }
}

/// A builder for [`FoundationModelSummary`](crate::types::FoundationModelSummary).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct FoundationModelSummaryBuilder {
    pub(crate) model_arn: ::std::option::Option<::std::string::String>,
    pub(crate) model_id: ::std::option::Option<::std::string::String>,
    pub(crate) model_name: ::std::option::Option<::std::string::String>,
    pub(crate) provider_name: ::std::option::Option<::std::string::String>,
    pub(crate) input_modalities: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>,
    pub(crate) output_modalities: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>,
    pub(crate) response_streaming_supported: ::std::option::Option<bool>,
    pub(crate) customizations_supported: ::std::option::Option<::std::vec::Vec<crate::types::ModelCustomization>>,
    pub(crate) inference_types_supported: ::std::option::Option<::std::vec::Vec<crate::types::InferenceType>>,
}
impl FoundationModelSummaryBuilder {
    /// <p>The ARN of the foundation model.</p>
    pub fn model_arn(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_arn = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The ARN of the foundation model.</p>
    pub fn set_model_arn(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_arn = input;
        self
    }
    /// <p>The ARN of the foundation model.</p>
    pub fn get_model_arn(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_arn
    }
    /// <p>The model Id of the foundation model.</p>
    pub fn model_id(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_id = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The model Id of the foundation model.</p>
    pub fn set_model_id(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_id = input;
        self
    }
    /// <p>The model Id of the foundation model.</p>
    pub fn get_model_id(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_id
    }
    /// <p>The name of the model.</p>
    pub fn model_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.model_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the model.</p>
    pub fn set_model_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.model_name = input;
        self
    }
    /// <p>The name of the model.</p>
    pub fn get_model_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.model_name
    }
    /// <p>The model's provider name.</p>
    pub fn provider_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.provider_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The model's provider name.</p>
    pub fn set_provider_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.provider_name = input;
        self
    }
    /// <p>The model's provider name.</p>
    pub fn get_provider_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.provider_name
    }
    /// Appends an item to `input_modalities`.
    ///
    /// To override the contents of this collection use [`set_input_modalities`](Self::set_input_modalities).
    ///
    /// <p>The input modalities that the model supports.</p>
    pub fn input_modalities(mut self, input: crate::types::ModelModality) -> Self {
        let mut v = self.input_modalities.unwrap_or_default();
        v.push(input);
        self.input_modalities = ::std::option::Option::Some(v);
        self
    }
    /// <p>The input modalities that the model supports.</p>
    pub fn set_input_modalities(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>) -> Self {
        self.input_modalities = input;
        self
    }
    /// <p>The input modalities that the model supports.</p>
    pub fn get_input_modalities(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ModelModality>> {
        &self.input_modalities
    }
    /// Appends an item to `output_modalities`.
    ///
    /// To override the contents of this collection use [`set_output_modalities`](Self::set_output_modalities).
    ///
    /// <p>The output modalities that the model supports.</p>
    pub fn output_modalities(mut self, input: crate::types::ModelModality) -> Self {
        let mut v = self.output_modalities.unwrap_or_default();
        v.push(input);
        self.output_modalities = ::std::option::Option::Some(v);
        self
    }
    /// <p>The output modalities that the model supports.</p>
    pub fn set_output_modalities(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ModelModality>>) -> Self {
        self.output_modalities = input;
        self
    }
    /// <p>The output modalities that the model supports.</p>
    pub fn get_output_modalities(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ModelModality>> {
        &self.output_modalities
    }
    /// <p>Indicates whether the model supports streaming.</p>
    pub fn response_streaming_supported(mut self, input: bool) -> Self {
        self.response_streaming_supported = ::std::option::Option::Some(input);
        self
    }
    /// <p>Indicates whether the model supports streaming.</p>
    pub fn set_response_streaming_supported(mut self, input: ::std::option::Option<bool>) -> Self {
        self.response_streaming_supported = input;
        self
    }
    /// <p>Indicates whether the model supports streaming.</p>
    pub fn get_response_streaming_supported(&self) -> &::std::option::Option<bool> {
        &self.response_streaming_supported
    }
    /// Appends an item to `customizations_supported`.
    ///
    /// To override the contents of this collection use [`set_customizations_supported`](Self::set_customizations_supported).
    ///
    /// <p>Whether the model supports fine-tuning or continual pre-training.</p>
    pub fn customizations_supported(mut self, input: crate::types::ModelCustomization) -> Self {
        let mut v = self.customizations_supported.unwrap_or_default();
        v.push(input);
        self.customizations_supported = ::std::option::Option::Some(v);
        self
    }
    /// <p>Whether the model supports fine-tuning or continual pre-training.</p>
    pub fn set_customizations_supported(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::ModelCustomization>>) -> Self {
        self.customizations_supported = input;
        self
    }
    /// <p>Whether the model supports fine-tuning or continual pre-training.</p>
    pub fn get_customizations_supported(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::ModelCustomization>> {
        &self.customizations_supported
    }
    /// Appends an item to `inference_types_supported`.
    ///
    /// To override the contents of this collection use [`set_inference_types_supported`](Self::set_inference_types_supported).
    ///
    /// <p>The inference types that the model supports.</p>
    pub fn inference_types_supported(mut self, input: crate::types::InferenceType) -> Self {
        let mut v = self.inference_types_supported.unwrap_or_default();
        v.push(input);
        self.inference_types_supported = ::std::option::Option::Some(v);
        self
    }
    /// <p>The inference types that the model supports.</p>
    pub fn set_inference_types_supported(mut self, input: ::std::option::Option<::std::vec::Vec<crate::types::InferenceType>>) -> Self {
        self.inference_types_supported = input;
        self
    }
    /// <p>The inference types that the model supports.</p>
    pub fn get_inference_types_supported(&self) -> &::std::option::Option<::std::vec::Vec<crate::types::InferenceType>> {
        &self.inference_types_supported
    }
    /// Consumes the builder and constructs a [`FoundationModelSummary`](crate::types::FoundationModelSummary).
    pub fn build(self) -> crate::types::FoundationModelSummary {
        crate::types::FoundationModelSummary {
            model_arn: self.model_arn,
            model_id: self.model_id,
            model_name: self.model_name,
            provider_name: self.provider_name,
            input_modalities: self.input_modalities,
            output_modalities: self.output_modalities,
            response_streaming_supported: self.response_streaming_supported,
            customizations_supported: self.customizations_supported,
            inference_types_supported: self.inference_types_supported,
        }
    }
}
